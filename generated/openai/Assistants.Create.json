{
  "moduleName": "OpenAI / Assistants / Create",
  "version": "0.0.0",
  "description": "Create an assistant with a model and instructions.",
  "keywords": [],
  "cacheMode": "always",
  "evalMode": "manual",
  "params": {
    "auth": {
      "schema": {
        "type": "string",
        "optional": true,
        "description": "OpenAI API key.\n"
      },
      "advanced": false,
      "hideValue": false
    },
    "betaAccess": {
      "schema": {
        "type": "string",
        "optional": false,
        "default": "assistants=v2",
        "description": "Adds OpenAI-Beta for access to new and experimental features."
      },
      "advanced": true,
      "hideValue": false
    },
    "model": {
      "schema": {
        "type": "string",
        "default": "gpt-4o",
        "optional": true,
        "description": "ID of the model to use.\n"
      },
      "advanced": false,
      "hideValue": false
    },
    "name": {
      "schema": {
        "type": "string",
        "optional": true,
        "description": "The name of the assistant. The maximum length is 256 characters.\n"
      },
      "advanced": true,
      "hideValue": false
    },
    "description": {
      "schema": {
        "type": "string",
        "optional": true,
        "description": "The description of the assistant. The maximum length is 512 characters.\n"
      },
      "advanced": true,
      "hideValue": false
    },
    "instructions": {
      "schema": {
        "type": "string",
        "optional": true,
        "description": "The system instructions that the assistant uses. The maximum length is 256,000 characters.\n"
      },
      "advanced": true,
      "hideValue": false
    },
    "tools": {
      "schema": {
        "type": "array",
        "items": {
          "type": "any"
        },
        "optional": true,
        "description": "A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n"
      },
      "advanced": true,
      "hideValue": false
    },
    "toolResources": {
      "schema": {
        "type": "any",
        "optional": true,
        "description": "A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n"
      },
      "advanced": true,
      "hideValue": true
    },
    "metadata": {
      "schema": {
        "type": "any",
        "optional": true,
        "description": "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.\n"
      },
      "advanced": true,
      "hideValue": true
    },
    "temperature": {
      "schema": {
        "type": "number",
        "default": "1",
        "minimum": 0,
        "maximum": 2,
        "optional": true,
        "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n"
      },
      "advanced": true,
      "hideValue": false
    },
    "topP": {
      "schema": {
        "type": "number",
        "default": "1",
        "minimum": 0,
        "maximum": 1,
        "optional": true,
        "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n"
      },
      "advanced": true,
      "hideValue": false
    },
    "responseFormat": {
      "schema": {
        "type": "any",
        "optional": true,
        "description": "Specifies the format that the model must output. Compatible with GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the message the model generates is valid JSON.\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n"
      },
      "advanced": true,
      "hideValue": true
    }
  },
  "result": {
    "schema": {
      "type": "any"
    },
    "async": true
  },
  "attributes": {
    "externalDocs": "https://platform.openai.com/docs/api-reference",
    "codeHash": "f7907f01a01fa394cbe68db3b9bd480f163f74c041f0bf82b17021b4c67e3005"
  }
}