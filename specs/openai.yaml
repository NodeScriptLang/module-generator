id: openai
displayName: OpenAI
baseUrl: https://api.openai.com/v1
description: The OpenAI REST API. Please see
  https://platform.openai.com/docs/api-reference for more details.
commonParams:
  - paramName: auth
    paramKey: Authorization
    in: header
    prefix: Bearer
    description: |
      OpenAI API key.
    required: true
    schema:
      type: string
  - paramName: betaAccess
    paramKey: OpenAI-Beta
    in: header
    description: Adds OpenAI-Beta for access to new and experimental features.
    schema:
      type: string
      default: assistants=v2
      optional: false
modules:
  - moduleName: Chat / Completions / Create
    operationId: createChatCompletion
    method: post
    path: /chat/completions
    description: Creates a model response for the given chat conversation.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: messages
        description: A list of messages comprising the conversation so far.
        paramKey: messages
        in: body
        schema:
          type: array
          items:
            type: any
        required: true
      - paramName: model
        description: ID of the model to use.
        paramKey: model
        in: body
        schema:
          type: string
          default: gpt-4o
        required: true
      - paramName: frequencyPenalty
        description: >
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on their existing frequency in the text so far, decreasing the model's
          likelihood to repeat the same line verbatim.
        paramKey: frequency_penalty
        in: body
        schema:
          type: number
          minimum: -2
          maximum: 2
          default: 0
        required: false
      - paramName: logitBias
        description: >
          Modify the likelihood of specified tokens appearing in the completion.
          Accepts a JSON object that maps tokens (specified by their token ID in
          the tokenizer) to an associated bias value from -100 to 100.
          Mathematically, the bias is added to the logits generated by the model
          prior to sampling. The exact effect will vary per model, but values
          between -1 and 1 should decrease or increase likelihood of selection;
          values like -100 or 100 should result in a ban or exclusive selection
          of the relevant token.
        paramKey: logit_bias
        in: body
        schema:
          type: any
        required: false
      - paramName: logprobs
        description: Whether to return log probabilities of the output tokens or not. If
          true, returns the log probabilities of each output token returned in
          the `content` of `message`.
        paramKey: logprobs
        in: body
        schema:
          type: boolean
          default: false
        required: false
      - paramName: topLogprobs
        description: An integer between 0 and 20 specifying the number of most likely
          tokens to return at each token position, each with an associated log
          probability. `logprobs` must be set to `true` if this parameter is
          used.
        paramKey: top_logprobs
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 20
        required: false
      - paramName: maxTokens
        description: >
          The maximum number of tokens that can be generated in
          the chat completion.

          The total length of input tokens and generated tokens is limited by
          the model's context length.
        paramKey: max_tokens
        in: body
        schema:
          type: number
        required: false
      - paramName: n
        description: How many chat completion choices to generate for each input
          message. Note that you will be charged based on the number of
          generated tokens across all of the choices. Keep `n` as `1` to
          minimize costs.
        paramKey: n
        in: body
        schema:
          type: number
          minimum: 1
          maximum: 128
          default: 1
        required: false
      - paramName: presencePenalty
        description: >
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on whether they appear in the text so far, increasing the model's
          likelihood to talk about new topics.
        paramKey: presence_penalty
        in: body
        schema:
          type: number
          minimum: -2
          maximum: 2
          default: 0
        required: false
      - paramName: responseFormat
        description: >
          An object specifying the format that the model must output. Compatible
          with GPT-4 Turbo and all GPT-3.5
          Turbo models newer than `gpt-3.5-turbo-1106`.

          Setting to `{ "type": "json_object" }` enables JSON mode, which
          guarantees the message the model generates is valid JSON.

          **Important:** when using JSON mode, you **must** also instruct the
          model to produce JSON yourself via a system or user message. Without
          this, the model may generate an unending stream of whitespace until
          the generation reaches the token limit, resulting in a long-running
          and seemingly "stuck" request. Also note that the message content may
          be partially cut off if `finish_reason="length"`, which indicates the
          generation exceeded `max_tokens` or the conversation exceeded the max
          context length.
        paramKey: response_format
        in: body
        schema:
          type: any
        required: false
      - paramName: seed
        description: >
          This feature is in Beta.

          If specified, our system will make a best effort to sample
          deterministically, such that repeated requests with the same `seed`
          and parameters should return the same result.

          Determinism is not guaranteed, and you should refer to the
          `system_fingerprint` response parameter to monitor changes in the
          backend.
        paramKey: seed
        in: body
        schema:
          type: number
          minimum: -9223372036854776000
          maximum: 9223372036854776000
        required: false
      - paramName: serviceTier
        description: >
          Specifies the latency tier to use for processing the request. This
          parameter is relevant for customers subscribed to the scale tier
          service:
            - If set to 'auto', the system will utilize scale tier credits until they are exhausted.
            - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
            - When not set, the default behavior is 'auto'.

            When this parameter is set, the response body will include the `service_tier` utilized.
        paramKey: service_tier
        in: body
        schema:
          type: string
          default: null
          enum:
            - auto
            - default
        required: false
      - paramName: stop
        description: |
          Up to 4 sequences where the API will stop generating further tokens.
        paramKey: stop
        in: body
        schema:
          type: any
        required: false
      - paramName: temperature
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
          We generally recommend altering this or `top_p` but not both.
        paramKey: temperature
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 2
          default: 1
        required: false
      - paramName: topP
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.
          We generally recommend altering this or `temperature` but not both.
        paramKey: top_p
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 1
          default: 1
        required: false
      - paramName: tools
        description: >
          A list of tools the model may call. Currently, only functions are
          supported as a tool. Use this to provide a list of functions the model
          may generate JSON inputs for. A max of 128 functions are supported.
        paramKey: tools
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: toolChoice
        description: >
          Controls which (if any) tool is called by the model.

          `none` means the model will not call any tool and instead generates a
          message.

          `auto` means the model can pick between generating a message or
          calling one or more tools.

          `required` means the model must call one or more tools.

          Specifying a particular tool via `{"type": "function", "function":
          {"name": "my_function"}}` forces the model to call that tool.


          `none` is the default when no tools are present. `auto` is the default
          if tools are present.
        paramKey: tool_choice
        in: body
        schema:
          type: any
        required: false
      - paramName: parallelToolCalls
        description: Whether to enable parallel function calling during tool use.
        paramKey: parallel_tool_calls
        in: body
        schema:
          type: boolean
        required: false
      - paramName: user
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse.
        paramKey: user
        in: body
        schema:
          type: string
        required: false
      - paramName: functionCall
        description: >
          Deprecated in favor of `tool_choice`.


          Controls which (if any) function is called by the model.

          `none` means the model will not call a function and instead generates
          a message.

          `auto` means the model can pick between generating a message or
          calling a function.

          Specifying a particular function via `{"name": "my_function"}` forces
          the model to call that function.


          `none` is the default when no functions are present. `auto` is the
          default if functions are present.
        paramKey: function_call
        in: body
        schema:
          type: any
        required: false
      - paramName: functions
        description: |
          Deprecated in favor of `tools`.

          A list of functions the model may generate JSON inputs for.
        paramKey: functions
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
    requestBodyType: json
  - moduleName: Completions / Create
    operationId: createCompletion
    method: post
    path: /completions
    description: Creates a completion for the provided prompt and parameters.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: model
        description: >
          ID of the model to use.
        paramKey: model
        in: body
        schema:
          type: string
          default: gpt-4o
        required: true
      - paramName: prompt
        description: >
          The prompt(s) to generate completions for, encoded as a string, array
          of strings, array of tokens, or array of token arrays.

          Note that <|endoftext|> is the document separator that the model sees
          during training, so if a prompt is not specified the model will
          generate as if from the beginning of a new document.
        paramKey: prompt
        in: body
        schema:
          type: any
        required: true
      - paramName: bestOf
        description: >
          Generates `best_of` completions server-side and returns the "best"
          (the one with the highest log probability per token). Results cannot
          be streamed.


          When used with `n`, `best_of` controls the number of candidate
          completions and `n` specifies how many to return – `best_of` must be
          greater than `n`.


          **Note:** Because this parameter generates many completions, it can
          quickly consume your token quota. Use carefully and ensure that you
          have reasonable settings for `max_tokens` and `stop`.
        paramKey: best_of
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 20
          default: 1
        required: false
      - paramName: echo
        description: |
          Echo back the prompt in addition to the completion
        paramKey: echo
        in: body
        schema:
          type: boolean
          default: false
        required: false
      - paramName: frequencyPenalty
        description: >
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on their existing frequency in the text so far, decreasing the model's
          likelihood to repeat the same line verbatim.
        paramKey: frequency_penalty
        in: body
        schema:
          type: number
          minimum: -2
          maximum: 2
          default: 0
        required: false
      - paramName: logitBias
        description: >
          Modify the likelihood of specified tokens appearing in the completion.

          Accepts a JSON object that maps tokens (specified by their token ID in
          the GPT tokenizer) to an associated bias value from -100 to 100. You
          can use tokenizer to convert text to token IDs.
          Mathematically, the bias is added to the logits generated
          by the model prior to sampling. The exact effect will vary per model,
          but values between -1 and 1 should decrease or increase likelihood of
          selection; values like -100 or 100 should result in a ban or exclusive
          selection of the relevant token.

          As an example, you can pass `{"50256": -100}` to prevent the
          <|endoftext|> token from being generated.
        paramKey: logit_bias
        in: body
        schema:
          type: any
        required: false
      - paramName: logprobs
        description: >
          Include the log probabilities on the `logprobs` most likely output
          tokens, as well the chosen tokens. For example, if `logprobs` is 5,
          the API will return a list of the 5 most likely tokens. The API will
          always return the `logprob` of the sampled token, so there may be up
          to `logprobs+1` elements in the response.
          The maximum value for `logprobs` is 5.
        paramKey: logprobs
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 5
          default: null
        required: false
      - paramName: maxTokens
        description: >
          The maximum number of tikens that can be generated in
          the completion.
          The token count of your prompt plus `max_tokens` cannot exceed the
          model's context length.
        paramKey: max_tokens
        in: body
        schema:
          type: number
          minimum: 0
          default: 16
        required: false
      - paramName: n
        description: >
          How many completions to generate for each prompt.
          **Note:** Because this parameter generates many completions, it can
          quickly consume your token quota. Use carefully and ensure that you
          have reasonable settings for `max_tokens` and `stop`.
        paramKey: n
        in: body
        schema:
          type: number
          minimum: 1
          maximum: 128
          default: 1
        required: false
      - paramName: presencePenalty
        description: >
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on whether they appear in the text so far, increasing the model's
          likelihood to talk about new topics.
        paramKey: presence_penalty
        in: body
        schema:
          type: number
          minimum: -2
          maximum: 2
          default: 0
        required: false
      - paramName: seed
        description: >
          If specified, our system will make a best effort to sample
          deterministically, such that repeated requests with the same `seed`
          and parameters should return the same result.


          Determinism is not guaranteed, and you should refer to the
          `system_fingerprint` response parameter to monitor changes in the
          backend.
        paramKey: seed
        in: body
        schema:
          type: number
          minimum: -9223372036854776000
          maximum: 9223372036854776000
        required: false
      - paramName: stop
        description: >
          Up to 4 sequences where the API will stop generating further tokens.
          The returned text will not contain the stop sequence.
        paramKey: stop
        in: body
        schema:
          type: any
        required: false
      - paramName: suffix
        description: |
          The suffix that comes after a completion of inserted text.

          This parameter is only supported for `gpt-3.5-turbo-instruct`.
        paramKey: suffix
        in: body
        schema:
          type: string
          default: null
        required: false
      - paramName: temperature
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
          We generally recommend altering this or `top_p` but not both.
        paramKey: temperature
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 2
          default: 1
        required: false
      - paramName: topP
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.
          We generally recommend altering this or `temperature` but not both.
        paramKey: top_p
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 1
          default: 1
        required: false
      - paramName: user
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse.
        paramKey: user
        in: body
        schema:
          type: string
        required: false
    requestBodyType: json
  - moduleName: Images / Generations / Create
    operationId: createImage
    method: post
    path: /images/generations
    description: Creates an image given a prompt.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: prompt
        description: A text description of the desired image(s). The maximum length is
          1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.
        paramKey: prompt
        in: body
        schema:
          type: string
        required: true
      - paramName: model
        description: The model to use for image generation.
        paramKey: model
        in: body
        schema:
          type: any
        required: false
      - paramName: n
        description: The number of images to generate. Must be between 1 and 10. For
          `dall-e-3`, only `n=1` is supported.
        paramKey: n
        in: body
        schema:
          type: number
          minimum: 1
          maximum: 10
          default: 1
        required: false
      - paramName: quality
        description: The quality of the image that will be generated. `hd` creates
          images with finer details and greater consistency across the image.
          This param is only supported for `dall-e-3`.
        paramKey: quality
        in: body
        schema:
          type: string
          default: standard
          enum:
            - standard
            - hd
        required: false
      - paramName: responseFormat
        description: The format in which the generated images are returned. Must be one
          of `url` or `b64_json`. URLs are only valid for 60 minutes after the
          image has been generated.
        paramKey: response_format
        in: body
        schema:
          type: string
          default: url
          enum:
            - url
            - b64_json
        required: false
      - paramName: size
        description: The size of the generated images. Must be one of `256x256`,
          `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`,
          `1792x1024`, or `1024x1792` for `dall-e-3` models.
        paramKey: size
        in: body
        schema:
          type: string
          default: 1024x1024
          enum:
            - 256x256
            - 512x512
            - 1024x1024
            - 1792x1024
            - 1024x1792
        required: false
      - paramName: style
        description: The style of the generated images. Must be one of `vivid` or
          `natural`. Vivid causes the model to lean towards generating
          hyper-real and dramatic images. Natural causes the model to produce
          more natural, less hyper-real looking images. This param is only
          supported for `dall-e-3`.
        paramKey: style
        in: body
        schema:
          type: string
          default: vivid
          enum:
            - vivid
            - natural
        required: false
      - paramName: user
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse.
        paramKey: user
        in: body
        schema:
          type: string
        required: false
    requestBodyType: json
  - moduleName: Embeddings / Create
    operationId: createEmbedding
    method: post
    path: /embeddings
    description: Creates an embedding vector representing the input text.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: input
        description: >
          Input text to embed, encoded as a string or array of tokens. To embed
          multiple inputs in a single request, pass an array of strings or array
          of token arrays. The input must not exceed the max input tokens for
          the model (8192 tokens for `text-embedding-ada-002`), cannot be an
          empty string, and any array must be 2048 dimensions or less.
        paramKey: input
        in: body
        schema:
          type: any
        required: true
      - paramName: model
        description: >
          ID of the model to use.
        paramKey: model
        in: body
        schema:
          type: string
          default: gpt-4o
        required: true
      - paramName: encodingFormat
        description: The format to return the embeddings in.
        paramKey: encoding_format
        in: body
        schema:
          type: string
          default: float
          enum:
            - float
            - base64
        required: false
      - paramName: dimensions
        description: >
          The number of dimensions the resulting output embeddings should have.
          Only supported in `text-embedding-3` and later models.
        paramKey: dimensions
        in: body
        schema:
          type: number
          minimum: 1
        required: false
      - paramName: user
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse.
        paramKey: user
        in: body
        schema:
          type: string
        required: false
    requestBodyType: json
  - moduleName: Audio / Speech / Create
    operationId: createSpeech
    method: post
    path: /audio/speech
    description: Generates audio from the input text.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: model
        description: >
          One of the available TTS models: `tts-1` or `tts-1-hd`
        paramKey: model
        in: body
        schema:
          type: any
        required: true
      - paramName: input
        description: The text to generate audio for. The maximum length is 4096 characters.
        paramKey: input
        in: body
        schema:
          type: string
        required: true
      - paramName: voice
        description: The voice to use when generating the audio. Supported voices are
          `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`.
        paramKey: voice
        in: body
        schema:
          type: string
          enum:
            - alloy
            - echo
            - fable
            - onyx
            - nova
            - shimmer
        required: true
      - paramName: responseFormat
        description: The format to audio in. Supported formats are `mp3`, `opus`, `aac`,
          `flac`, `wav`, and `pcm`.
        paramKey: response_format
        in: body
        schema:
          type: string
          default: mp3
          enum:
            - mp3
            - opus
            - aac
            - flac
            - wav
            - pcm
        required: false
      - paramName: speed
        description: The speed of the generated audio. Select a value from `0.25` to
          `4.0`. `1.0` is the default.
        paramKey: speed
        in: body
        schema:
          type: number
          minimum: 0.25
          maximum: 4
          default: 1
        required: false
    requestBodyType: json
  - moduleName: Files / List
    operationId: listFiles
    method: get
    path: /files
    description: Returns a list of files that belong to the user's organization.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: purpose
        description: Only return files with the given purpose.
        paramKey: purpose
        in: query
        schema:
          type: string
        required: false
  - moduleName: Files / Delete
    operationId: deleteFile
    method: delete
    path: /files/{file_id}
    description: Delete a file.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: fileId
        description: The ID of the file to use for this request.
        paramKey: file_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Files / Retrieve
    operationId: retrieveFile
    method: get
    path: /files/{file_id}
    description: Returns information about a specific file.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: fileId
        description: The ID of the file to use for this request.
        paramKey: file_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Files / Content / Retrieve
    operationId: downloadFile
    method: get
    path: /files/{file_id}/content
    description: Returns the contents of the specified file.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: fileId
        description: The ID of the file to use for this request.
        paramKey: file_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Uploads / Create
    operationId: createUpload
    method: post
    path: /uploads
    description: >
      Creates an intermediate Upload object that you can add Parts to.
      Currently, an Upload can accept at most 8 GB in total and expires
      after an hour after you create it.
      Once you complete the Upload, we will create a
      File object that contains all the
      parts you uploaded. This File is usable in the rest of our platform as a
      regular File object.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: filename
        description: |
          The name of the file to upload.
        paramKey: filename
        in: body
        schema:
          type: string
        required: true
      - paramName: purpose
        description: >
          The intended purpose of the uploaded file.
        paramKey: purpose
        in: body
        schema:
          type: string
          enum:
            - assistants
            - batch
            - fine-tune
            - vision
        required: true
      - paramName: bytes
        description: |
          The number of bytes in the file you are uploading.
        paramKey: bytes
        in: body
        schema:
          type: number
        required: true
      - paramName: mimeType
        description: >
          The MIME type of the file.
          This must fall within the supported MIME types for your file purpose.
          See the supported MIME types for assistants and vision.
        paramKey: mime_type
        in: body
        schema:
          type: string
        required: true
    requestBodyType: json
  - moduleName: Uploads / Complete
    operationId: completeUpload
    method: post
    path: /uploads/{upload_id}/complete
    description: >
      Completes the Upload.

      Within the returned Upload object, there is a nested
      File object that is ready to use in
      the rest of the platform.

      You can specify the order of the Parts by passing in an ordered list of
      the Part IDs.

      The number of bytes uploaded upon completion must match the number of
      bytes initially specified when creating the Upload object. No Parts may be
      added after an Upload is completed.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: uploadId
        description: |
          The ID of the Upload.
        paramKey: upload_id
        in: path
        schema:
          type: string
        required: true
      - paramName: partIds
        description: |
          The ordered list of Part IDs.
        paramKey: part_ids
        in: body
        schema:
          type: array
          items:
            type: any
        required: true
      - paramName: md5
        description: >
          The optional md5 checksum for the file contents to verify if the bytes
          uploaded matches what you expect.
        paramKey: md5
        in: body
        schema:
          type: string
        required: false
    requestBodyType: json
  - moduleName: Uploads / Cancel
    operationId: cancelUpload
    method: post
    path: /uploads/{upload_id}/cancel
    description: |
      Cancels the Upload. No Parts may be added after an Upload is cancelled.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: uploadId
        description: |
          The ID of the Upload.
        paramKey: upload_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Fine Tuning / Jobs / Create
    operationId: createFineTuningJob
    method: post
    path: /fine_tuning/jobs
    description: >
      Creates a fine-tuning job which begins the process of creating a new model
      from a given dataset.

      Response includes details of the enqueued job including job status and the
      name of the fine-tuned models once complete.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: model
        description: >
          The name of the model to fine-tune. You can select one of the
        paramKey: model
        in: body
        schema:
          type: any
        required: true
      - paramName: trainingFile
        description: >
          The ID of an uploaded file that contains training data.

          Your dataset must be formatted as a JSONL file. Additionally, you must
          upload your file with the purpose `fine-tune`.

          The contents of the file should differ depending on if the model uses
          the chat or completions format.

          See the fine-tuning for more
          details.
        paramKey: training_file
        in: body
        schema:
          type: string
        required: true
      - paramName: hyperparameters
        description: The hyperparameters used for the fine-tuning job.
        paramKey: hyperparameters
        in: body
        schema:
          type: any
        required: false
      - paramName: suffix
        description: >
          A string of up to 18 characters that will be added to your fine-tuned
          model name.


          For example, a `suffix` of "custom-model-name" would produce a model
          name like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
        paramKey: suffix
        in: body
        schema:
          type: string
          default: null
        required: false
      - paramName: validationFile
        description: >
          The ID of an uploaded file that contains validation data.

          If you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed
          in the fine-tuning results file.

          The same data should not be present in both train and validation
          files.

          Your dataset must be formatted as a JSONL file. You must upload your
          file with the purpose `fine-tune`.

        paramKey: validation_file
        in: body
        schema:
          type: string
        required: false
      - paramName: integrations
        description: A list of integrations to enable for your fine-tuning job.
        paramKey: integrations
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: seed
        description: >
          The seed controls the reproducibility of the job. Passing in the same
          seed and job parameters should produce the same results, but may
          differ in rare cases.

          If a seed is not specified, one will be generated for you.
        paramKey: seed
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 2147483647
        required: false
    requestBodyType: json
  - moduleName: Fine Tuning / Jobs / List
    operationId: listPaginatedFineTuningJobs
    method: get
    path: /fine_tuning/jobs
    description: |
      List your organization's fine-tuning jobs
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: after
        description: Identifier for the last job from the previous pagination request.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: limit
        description: Number of fine-tuning jobs to retrieve.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
  - moduleName: Fine Tuning / Jobs / Retrieve
    operationId: retrieveFineTuningJob
    method: get
    path: /fine_tuning/jobs/{fine_tuning_job_id}
    description: |
      Get info about a fine-tuning job.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: fineTuningJobId
        description: |
          The ID of the fine-tuning job.
        paramKey: fine_tuning_job_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Fine Tuning / Jobs / Events / List
    operationId: listFineTuningEvents
    method: get
    path: /fine_tuning/jobs/{fine_tuning_job_id}/events
    description: |
      Get status updates for a fine-tuning job.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: fineTuningJobId
        description: |
          The ID of the fine-tuning job to get events for.
        paramKey: fine_tuning_job_id
        in: path
        schema:
          type: string
        required: true
      - paramName: after
        description: Identifier for the last event from the previous pagination request.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: limit
        description: Number of events to retrieve.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
  - moduleName: Fine Tuning / Jobs / Cancel
    operationId: cancelFineTuningJob
    method: post
    path: /fine_tuning/jobs/{fine_tuning_job_id}/cancel
    description: |
      Immediately cancel a fine-tune job.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: fineTuningJobId
        description: |
          The ID of the fine-tuning job to cancel.
        paramKey: fine_tuning_job_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Fine Tuning / Jobs / Checkpoints / List
    operationId: listFineTuningJobCheckpoints
    method: get
    path: /fine_tuning/jobs/{fine_tuning_job_id}/checkpoints
    description: |
      List checkpoints for a fine-tuning job.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: fineTuningJobId
        description: |
          The ID of the fine-tuning job to get checkpoints for.
        paramKey: fine_tuning_job_id
        in: path
        schema:
          type: string
        required: true
      - paramName: after
        description: Identifier for the last checkpoint ID from the previous pagination
          request.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: limit
        description: Number of checkpoints to retrieve.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 10
        required: false
  - moduleName: Models / List
    operationId: listModels
    method: get
    path: /models
    description: Lists the currently available models, and provides basic
      information about each one such as the owner and availability.
    externalDocs: https://platform.openai.com/docs/api-reference
    params: []
  - moduleName: Models / Retrieve
    operationId: retrieveModel
    method: get
    path: /models/{model}
    description: Retrieves a model instance, providing basic information about the
      model such as the owner and permissioning.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: model
        description: The ID of the model to use for this request
        paramKey: model
        in: path
        schema:
          type: string
        required: true
  - moduleName: Models / Delete
    operationId: deleteModel
    method: delete
    path: /models/{model}
    description: Delete a fine-tuned model. You must have the Owner role in your
      organization to delete a model.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: model
        description: The model to delete
        paramKey: model
        in: path
        schema:
          type: string
        required: true
  - moduleName: Moderations / Create
    operationId: createModeration
    method: post
    path: /moderations
    description: Classifies if text is potentially harmful.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: input
        description: The input text to classify
        paramKey: input
        in: body
        schema:
          type: any
        required: true
      - paramName: model
        description: >
          Two content moderations models are available: `text-moderation-stable`
          and `text-moderation-latest`.

          The default is `text-moderation-latest` which will be automatically
          upgraded over time. This ensures you are always using our most
          accurate model. If you use `text-moderation-stable`, we will provide
          advanced notice before updating the model. Accuracy of
          `text-moderation-stable` may be slightly lower than for
          `text-moderation-latest`.
        paramKey: model
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Assistants / List
    operationId: listAssistants
    method: get
    path: /assistants
    description: Returns a list of assistants.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: limit
        description: >
          A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
      - paramName: order
        description: >
          Sort order by the `created_at` timestamp of the objects. `asc` for
          ascending order and `desc` for descending order.
        paramKey: order
        in: query
        schema:
          type: string
          default: desc
          enum:
            - asc
            - desc
        required: false
      - paramName: after
        description: >
          A cursor for use in pagination. `after` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include after=obj_foo in order to fetch the next page of the list.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: before
        description: >
          A cursor for use in pagination. `before` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include before=obj_foo in order to fetch the previous page of the
          list.
        paramKey: before
        in: query
        schema:
          type: string
        required: false
  - moduleName: Assistants / Create
    operationId: createAssistant
    method: post
    path: /assistants
    description: Create an assistant with a model and instructions.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: model
        description: >
          ID of the model to use.
        paramKey: model
        in: body
        schema:
          type: string
          default: 'gpt-4o'
        required: true
      - paramName: name
        description: |
          The name of the assistant. The maximum length is 256 characters.
        paramKey: name
        in: body
        schema:
          type: string
        required: false
      - paramName: description
        description: >
          The description of the assistant. The maximum length is 512 characters.
        paramKey: description
        in: body
        schema:
          type: string
        required: false
      - paramName: instructions
        description: >
          The system instructions that the assistant uses. The maximum length is
          256,000 characters.
        paramKey: instructions
        in: body
        schema:
          type: string
        required: false
      - paramName: tools
        description: >
          A list of tool enabled on the assistant. There can be a maximum of 128
          tools per assistant. Tools can be of types `code_interpreter`,
          `file_search`, or `function`.
        paramKey: tools
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: toolResources
        description: >
          A set of resources that are used by the assistant's tools. The
          resources are specific to the type of tool. For example, the
          `code_interpreter` tool requires a list of file IDs, while the
          `file_search` tool requires a list of vector store IDs.
        paramKey: tool_resources
        in: body
        schema:
          type: any
        required: false
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
      - paramName: temperature
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
        paramKey: temperature
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 2
          default: 1
        required: false
      - paramName: topP
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or temperature but not both.
        paramKey: top_p
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 1
          default: 1
        required: false
      - paramName: responseFormat
        description: >
          Specifies the format that the model must output. Compatible with
          GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

          Setting to `{ "type": "json_object" }` enables JSON mode, which
          guarantees the message the model generates is valid JSON.

          **Important:** when using JSON mode, you **must** also instruct the
          model to produce JSON yourself via a system or user message. Without
          this, the model may generate an unending stream of whitespace until
          the generation reaches the token limit, resulting in a long-running
          and seemingly "stuck" request. Also note that the message content may
          be partially cut off if `finish_reason="length"`, which indicates the
          generation exceeded `max_tokens` or the conversation exceeded the max
          context length.
        paramKey: response_format
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Assistants / Retrieve
    operationId: getAssistant
    method: get
    path: /assistants/{assistant_id}
    description: Retrieves an assistant.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: assistantId
        description: The ID of the assistant to retrieve.
        paramKey: assistant_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Assistants / Modify
    operationId: modifyAssistant
    method: post
    path: /assistants/{assistant_id}
    description: Modifies an assistant.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: assistantId
        description: The ID of the assistant to modify.
        paramKey: assistant_id
        in: path
        schema:
          type: string
        required: true
      - paramName: model
        description: >
          ID of the model to use.
        paramKey: model
        in: body
        schema:
          type: string
          default: gpt-4o
        required: false
      - paramName: name
        description: |
          The name of the assistant. The maximum length is 256 characters.
        paramKey: name
        in: body
        schema:
          type: string
        required: false
      - paramName: description
        description: >
          The description of the assistant. The maximum length is 512 characters.
        paramKey: description
        in: body
        schema:
          type: string
        required: false
      - paramName: instructions
        description: >
          The system instructions that the assistant uses. The maximum length is
          256,000 characters.
        paramKey: instructions
        in: body
        schema:
          type: string
        required: false
      - paramName: tools
        description: >
          A list of tool enabled on the assistant. There can be a maximum of 128
          tools per assistant. Tools can be of types `code_interpreter`,
          `file_search`, or `function`.
        paramKey: tools
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: toolResources
        description: >
          A set of resources that are used by the assistant's tools. The
          resources are specific to the type of tool. For example, the
          `code_interpreter` tool requires a list of file IDs, while the
          `file_search` tool requires a list of vector store IDs.
        paramKey: tool_resources
        in: body
        schema:
          type: any
        required: false
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
      - paramName: temperature
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
        paramKey: temperature
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 2
          default: 1
        required: false
      - paramName: topP
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or temperature but not both.
        paramKey: top_p
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 1
          default: 1
        required: false
      - paramName: responseFormat
        description: >
          Specifies the format that the model must output. Compatible with
          GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

          Setting to `{ "type": "json_object" }` enables JSON mode, which
          guarantees the message the model generates is valid JSON.

          **Important:** when using JSON mode, you **must** also instruct the
          model to produce JSON yourself via a system or user message. Without
          this, the model may generate an unending stream of whitespace until
          the generation reaches the token limit, resulting in a long-running
          and seemingly "stuck" request. Also note that the message content may
          be partially cut off if `finish_reason="length"`, which indicates the
          generation exceeded `max_tokens` or the conversation exceeded the max
          context length.
        paramKey: response_format
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Assistants / Delete
    operationId: deleteAssistant
    method: delete
    path: /assistants/{assistant_id}
    description: Delete an assistant.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: assistantId
        description: The ID of the assistant to delete.
        paramKey: assistant_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Threads / Create
    operationId: createThread
    method: post
    path: /threads
    description: Create a thread.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: messages
        description: A list of messages to start the
          thread with.
        paramKey: messages
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: toolResources
        description: >
          A set of resources that are made available to the assistant's tools in
          this thread. The resources are specific to the type of tool. For
          example, the `code_interpreter` tool requires a list of file IDs,
          while the `file_search` tool requires a list of vector store IDs.
        paramKey: tool_resources
        in: body
        schema:
          type: any
        required: false
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Threads / Retrieve
    operationId: getThread
    method: get
    path: /threads/{thread_id}
    description: Retrieves a thread.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread to retrieve.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Threads / Modify
    operationId: modifyThread
    method: post
    path: /threads/{thread_id}
    description: Modifies a thread.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread to modify. Only the `metadata` can be modified.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: toolResources
        description: >
          A set of resources that are made available to the assistant's tools in
          this thread. The resources are specific to the type of tool. For
          example, the `code_interpreter` tool requires a list of file IDs,
          while the `file_search` tool requires a list of vector store IDs.
        paramKey: tool_resources
        in: body
        schema:
          type: any
        required: false
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Threads / Delete
    operationId: deleteThread
    method: delete
    path: /threads/{thread_id}
    description: Delete a thread.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread to delete.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Threads / Messages / List
    operationId: listMessages
    method: get
    path: /threads/{thread_id}/messages
    description: Returns a list of messages for a given thread.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the threads the messages
          belong to.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: limit
        description: >
          A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
      - paramName: order
        description: >
          Sort order by the `created_at` timestamp of the objects. `asc` for
          ascending order and `desc` for descending order.
        paramKey: order
        in: query
        schema:
          type: string
          default: desc
          enum:
            - asc
            - desc
        required: false
      - paramName: after
        description: >
          A cursor for use in pagination. `after` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include after=obj_foo in order to fetch the next page of the list.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: before
        description: >
          A cursor for use in pagination. `before` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include before=obj_foo in order to fetch the previous page of the
          list.
        paramKey: before
        in: query
        schema:
          type: string
        required: false
      - paramName: runId
        description: |
          Filter messages by the run ID that generated them.
        paramKey: run_id
        in: query
        schema:
          type: string
        required: false
  - moduleName:  Threads / Messages / Create
    operationId: createMessage
    method: post
    path: /threads/{thread_id}/messages
    description: Create a message.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the threads to create a
          message for.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: role
        description: >
          The role of the entity that is creating the message. Allowed values
          include:

          - `user`: Indicates the message is sent by an actual user and should
          be used in most cases to represent user-generated messages.

          - `assistant`: Indicates the message is generated by the assistant.
          Use this value to insert messages from the assistant into the
          conversation.
        paramKey: role
        in: body
        schema:
          type: string
          enum:
            - user
            - assistant
        required: true
      - paramName: content
        description: ""
        paramKey: content
        in: body
        schema:
          type: any
        required: true
      - paramName: attachments
        description: A list of files attached to the message, and the tools they should
          be added to.
        paramKey: attachments
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName:  Threads / Messages / Retrieve
    operationId: getMessage
    method: get
    path: /threads/{thread_id}/messages/{message_id}
    description: Retrieve a message.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the threads to which this
          message belongs.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: messageId
        description: The ID of the message to retrieve.
        paramKey: message_id
        in: path
        schema:
          type: string
        required: true
  - moduleName:  Threads / Messages / Modify
    operationId: modifyMessage
    method: post
    path: /threads/{thread_id}/messages/{message_id}
    description: Modifies a message.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread to which this message belongs.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: messageId
        description: The ID of the message to modify.
        paramKey: message_id
        in: path
        schema:
          type: string
        required: true
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName:  Threads / Messages / Delete
    operationId: deleteMessage
    method: delete
    path: /threads/{thread_id}/messages/{message_id}
    description: Deletes a message.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread to which this message belongs.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: messageId
        description: The ID of the message to delete.
        paramKey: message_id
        in: path
        schema:
          type: string
        required: true
  - moduleName:  Threads / Runs / Create And Run
    operationId: createThreadAndRun
    method: post
    path: /threads/runs
    description: Create a thread and run it in one request.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: assistantId
        description: The ID of the assistant to use to execute this run.
        paramKey: assistant_id
        in: body
        schema:
          type: string
        required: true
      - paramName: thread
        description: ""
        paramKey: thread
        in: body
        schema:
          type: any
        required: false
      - paramName: model
        description: The ID of the model to be used to
          execute this run. If a value is provided here, it will override the
          model associated with the assistant. If not, the model associated with
          the assistant will be used.
        paramKey: model
        in: body
        schema:
          type: any
        required: false
      - paramName: instructions
        description: Override the default system message of the assistant. This is
          useful for modifying the behavior on a per-run basis.
        paramKey: instructions
        in: body
        schema:
          type: string
        required: false
      - paramName: tools
        description: Override the tools the assistant can use for this run. This is
          useful for modifying the behavior on a per-run basis.
        paramKey: tools
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: toolResources
        description: >
          A set of resources that are used by the assistant's tools. The
          resources are specific to the type of tool. For example, the
          `code_interpreter` tool requires a list of file IDs, while the
          `file_search` tool requires a list of vector store IDs.
        paramKey: tool_resources
        in: body
        schema:
          type: any
        required: false
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
      - paramName: temperature
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
        paramKey: temperature
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 2
          default: 1
        required: false
      - paramName: topP
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or temperature but not both.
        paramKey: top_p
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 1
          default: 1
        required: false
      - paramName: stream
        description: >
          If `true`, returns a stream of events that happen during the Run as
          server-sent events, terminating when the Run enters a terminal state
          with a `data: [DONE]` message.
        paramKey: stream
        in: body
        schema:
          type: boolean
        required: false
      - paramName: maxPromptTokens
        description: >
          The maximum number of prompt tokens that may be used over the course
          of the run. The run will make a best effort to use only the number of
          prompt tokens specified, across multiple turns of the run. If the run
          exceeds the number of prompt tokens specified, the run will end with
          status `incomplete`. See `incomplete_details` for more info.
        paramKey: max_prompt_tokens
        in: body
        schema:
          type: number
          minimum: 256
        required: false
      - paramName: maxCompletionTokens
        description: >
          The maximum number of completion tokens that may be used over the
          course of the run. The run will make a best effort to use only the
          number of completion tokens specified, across multiple turns of the
          run. If the run exceeds the number of completion tokens specified, the
          run will end with status `incomplete`. See `incomplete_details` for
          more info.
        paramKey: max_completion_tokens
        in: body
        schema:
          type: number
          minimum: 256
        required: false
      - paramName: truncationStrategy
        description: Controls for how a thread will be truncated prior to the run. Use
          this to control the intial context window of the run.
        paramKey: truncation_strategy
        in: body
        schema:
          type: any
        required: false
      - paramName: toolChoice
        description: >
          Controls which (if any) tool is called by the model.

          `none` means the model will not call any tools and instead generates a
          message.

          `auto` is the default value and means the model can pick between
          generating a message or calling one or more tools.

          `required` means the model must call one or more tools before
          responding to the user.

          Specifying a particular tool like `{"type": "file_search"}` or
          `{"type": "function", "function": {"name": "my_function"}}` forces the
          model to call that tool.
        paramKey: tool_choice
        in: body
        schema:
          type: any
        required: false
      - paramName: parallelToolCalls
        description: Whether to enable parallel function calling during tool use.
        paramKey: parallel_tool_calls
        in: body
        schema:
          type: boolean
        required: false
      - paramName: responseFormat
        description: >
          Specifies the format that the model must output. Compatible with
          GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

          Setting to `{ "type": "json_object" }` enables JSON mode, which
          guarantees the message the model generates is valid JSON.

          **Important:** when using JSON mode, you **must** also instruct the
          model to produce JSON yourself via a system or user message. Without
          this, the model may generate an unending stream of whitespace until
          the generation reaches the token limit, resulting in a long-running
          and seemingly "stuck" request. Also note that the message content may
          be partially cut off if `finish_reason="length"`, which indicates the
          generation exceeded `max_tokens` or the conversation exceeded the max
          context length.
        paramKey: response_format
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName:  Threads / Runs / List
    operationId: listRuns
    method: get
    path: /threads/{thread_id}/runs
    description: Returns a list of runs belonging to a thread.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread the run belongs to.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: limit
        description: >
          A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
      - paramName: order
        description: >
          Sort order by the `created_at` timestamp of the objects. `asc` for
          ascending order and `desc` for descending order.
        paramKey: order
        in: query
        schema:
          type: string
          default: desc
          enum:
            - asc
            - desc
        required: false
      - paramName: after
        description: >
          A cursor for use in pagination. `after` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include after=obj_foo in order to fetch the next page of the list.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: before
        description: >
          A cursor for use in pagination. `before` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include before=obj_foo in order to fetch the previous page of the
          list.
        paramKey: before
        in: query
        schema:
          type: string
        required: false
  - moduleName:  Threads / Runs / Create
    operationId: createRun
    method: post
    path: /threads/{thread_id}/runs
    description: Create a run.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread to run.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: assistantId
        description: The ID of the assistant to use to
          execute this run.
        paramKey: assistant_id
        in: body
        schema:
          type: string
        required: true
      - paramName: model
        description: The ID of the model to be used to
          execute this run. If a value is provided here, it will override the
          model associated with the assistant. If not, the model associated with
          the assistant will be used.
        paramKey: model
        in: body
        schema:
          type: any
        required: false
      - paramName: instructions
        description: Overrides the instructions of the assistant. This is useful for modifying the behavior on a per-run basis.
        paramKey: instructions
        in: body
        schema:
          type: string
        required: false
      - paramName: additionalInstructions
        description: Appends additional instructions at the end of the instructions for
          the run. This is useful for modifying the behavior on a per-run basis
          without overriding other instructions.
        paramKey: additional_instructions
        in: body
        schema:
          type: string
        required: false
      - paramName: additionalMessages
        description: Adds additional messages to the thread before creating the run.
        paramKey: additional_messages
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: tools
        description: Override the tools the assistant can use for this run. This is
          useful for modifying the behavior on a per-run basis.
        paramKey: tools
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
      - paramName: temperature
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
        paramKey: temperature
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 2
          default: 1
        required: false
      - paramName: topP
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or temperature but not both.
        paramKey: top_p
        in: body
        schema:
          type: number
          minimum: 0
          maximum: 1
          default: 1
        required: false
      - paramName: stream
        description: >
          If `true`, returns a stream of events that happen during the Run as
          server-sent events, terminating when the Run enters a terminal state
          with a `data: [DONE]` message.
        paramKey: stream
        in: body
        schema:
          type: boolean
        required: false
      - paramName: maxPromptTokens
        description: >
          The maximum number of prompt tokens that may be used over the course
          of the run. The run will make a best effort to use only the number of
          prompt tokens specified, across multiple turns of the run. If the run
          exceeds the number of prompt tokens specified, the run will end with
          status `incomplete`. See `incomplete_details` for more info.
        paramKey: max_prompt_tokens
        in: body
        schema:
          type: number
          minimum: 256
        required: false
      - paramName: maxCompletionTokens
        description: >
          The maximum number of completion tokens that may be used over the
          course of the run. The run will make a best effort to use only the
          number of completion tokens specified, across multiple turns of the
          run. If the run exceeds the number of completion tokens specified, the
          run will end with status `incomplete`. See `incomplete_details` for
          more info.
        paramKey: max_completion_tokens
        in: body
        schema:
          type: number
          minimum: 256
        required: false
      - paramName: truncationStrategy
        description: Controls for how a thread will be truncated prior to the run. Use
          this to control the intial context window of the run.
        paramKey: truncation_strategy
        in: body
        schema:
          type: any
        required: false
      - paramName: toolChoice
        description: >
          Controls which (if any) tool is called by the model.

          `none` means the model will not call any tools and instead generates a
          message.

          `auto` is the default value and means the model can pick between
          generating a message or calling one or more tools.

          `required` means the model must call one or more tools before
          responding to the user.

          Specifying a particular tool like `{"type": "file_search"}` or
          `{"type": "function", "function": {"name": "my_function"}}` forces the
          model to call that tool.
        paramKey: tool_choice
        in: body
        schema:
          type: any
        required: false
      - paramName: parallelToolCalls
        description: Whether to enable parallel function calling during tool use.
        paramKey: parallel_tool_calls
        in: body
        schema:
          type: boolean
        required: false
      - paramName: responseFormat
        description: >
          Specifies the format that the model must output. Compatible with
          GPT-4o, GPT-4 Turbo, and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

          Setting to `{ "type": "json_object" }` enables JSON mode, which
          guarantees the message the model generates is valid JSON.

          **Important:** when using JSON mode, you **must** also instruct the
          model to produce JSON yourself via a system or user message. Without
          this, the model may generate an unending stream of whitespace until
          the generation reaches the token limit, resulting in a long-running
          and seemingly "stuck" request. Also note that the message content may
          be partially cut off if `finish_reason="length"`, which indicates the
          generation exceeded `max_tokens` or the conversation exceeded the max
          context length.
        paramKey: response_format
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName:  Threads / Runs / Retrieve
    operationId: getRun
    method: get
    path: /threads/{thread_id}/runs/{run_id}
    description: Retrieves a run.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread that was run.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: runId
        description: The ID of the run to retrieve.
        paramKey: run_id
        in: path
        schema:
          type: string
        required: true
  - moduleName:  Threads / Runs / Modify
    operationId: modifyRun
    method: post
    path: /threads/{thread_id}/runs/{run_id}
    description: Modifies a run.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread that was run.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: runId
        description: The ID of the run to modify.
        paramKey: run_id
        in: path
        schema:
          type: string
        required: true
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName:  Threads / Runs / Submit Tool Outputs
    operationId: submitToolOutputsToRun
    method: post
    path: /threads/{thread_id}/runs/{run_id}/submit_tool_outputs
    description: >
      When a run has the `status: "requires_action"` and `required_action.type`
      is `submit_tool_outputs`, this endpoint can be used to submit the outputs
      from the tool calls once they're all completed. All outputs must be
      submitted in a single request.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread to which this
          run belongs.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: runId
        description: The ID of the run that requires the tool output submission.
        paramKey: run_id
        in: path
        schema:
          type: string
        required: true
      - paramName: toolOutputs
        description: A list of tools for which the outputs are being submitted.
        paramKey: tool_outputs
        in: body
        schema:
          type: array
          items:
            type: any
        required: true
      - paramName: stream
        description: >
          If `true`, returns a stream of events that happen during the Run as
          server-sent events, terminating when the Run enters a terminal state
          with a `data: [DONE]` message.
        paramKey: stream
        in: body
        schema:
          type: boolean
        required: false
    requestBodyType: json
  - moduleName:  Threads / Runs / Cancel
    operationId: cancelRun
    method: post
    path: /threads/{thread_id}/runs/{run_id}/cancel
    description: Cancels a run that is `in_progress`.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread to which this run belongs.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: runId
        description: The ID of the run to cancel.
        paramKey: run_id
        in: path
        schema:
          type: string
        required: true
  - moduleName:  Threads / Runs / Steps / List
    operationId: listRunSteps
    method: get
    path: /threads/{thread_id}/runs/{run_id}/steps
    description: Returns a list of run steps belonging to a run.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread the run and run steps belong to.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: runId
        description: The ID of the run the run steps belong to.
        paramKey: run_id
        in: path
        schema:
          type: string
        required: true
      - paramName: limit
        description: >
          A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
      - paramName: order
        description: >
          Sort order by the `created_at` timestamp of the objects. `asc` for
          ascending order and `desc` for descending order.
        paramKey: order
        in: query
        schema:
          type: string
          default: desc
          enum:
            - asc
            - desc
        required: false
      - paramName: after
        description: >
          A cursor for use in pagination. `after` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include after=obj_foo in order to fetch the next page of the list.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: before
        description: >
          A cursor for use in pagination. `before` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include before=obj_foo in order to fetch the previous page of the
          list.
        paramKey: before
        in: query
        schema:
          type: string
        required: false
  - moduleName:  Threads / Runs / Steps / Retrieve
    operationId: getRunStep
    method: get
    path: /threads/{thread_id}/runs/{run_id}/steps/{step_id}
    description: Retrieves a run step.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: threadId
        description: The ID of the thread to which the run and run step belongs.
        paramKey: thread_id
        in: path
        schema:
          type: string
        required: true
      - paramName: runId
        description: The ID of the run to which the run step belongs.
        paramKey: run_id
        in: path
        schema:
          type: string
        required: true
      - paramName: stepId
        description: The ID of the run step to retrieve.
        paramKey: step_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Vector Stores / List
    operationId: listVectorStores
    method: get
    path: /vector_stores
    description: Returns a list of vector stores.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: limit
        description: >
          A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
      - paramName: order
        description: >
          Sort order by the `created_at` timestamp of the objects. `asc` for
          ascending order and `desc` for descending order.
        paramKey: order
        in: query
        schema:
          type: string
          default: desc
          enum:
            - asc
            - desc
        required: false
      - paramName: after
        description: >
          A cursor for use in pagination. `after` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include after=obj_foo in order to fetch the next page of the list.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: before
        description: >
          A cursor for use in pagination. `before` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include before=obj_foo in order to fetch the previous page of the
          list.
        paramKey: before
        in: query
        schema:
          type: string
        required: false
  - moduleName: Vector Stores / Create
    operationId: createVectorStore
    method: post
    path: /vector_stores
    description: Create a vector store.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: fileIds
        description: A list of File IDs that the vector
          store should use. Useful for tools like `file_search` that can access
          files.
        paramKey: file_ids
        in: body
        schema:
          type: array
          items:
            type: any
        required: false
      - paramName: name
        description: The name of the vector store.
        paramKey: name
        in: body
        schema:
          type: string
        required: false
      - paramName: expiresAfter
        description: The expiration policy for a vector store.
        paramKey: expires_after
        in: body
        schema:
          type: any
        required: false
      - paramName: chunkingStrategy
        description: The chunking strategy used to chunk the file(s). If not set, will
          use the `auto` strategy. Only applicable if `file_ids` is non-empty.
        paramKey: chunking_strategy
        in: body
        schema:
          type: any
        required: false
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Vector Stores / Retrieve
    operationId: getVectorStore
    method: get
    path: /vector_stores/{vector_store_id}
    description: Retrieves a vector store.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: The ID of the vector store to retrieve.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Vector Stores / Modify
    operationId: modifyVectorStore
    method: post
    path: /vector_stores/{vector_store_id}
    description: Modifies a vector store.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: The ID of the vector store to modify.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
      - paramName: name
        description: The name of the vector store.
        paramKey: name
        in: body
        schema:
          type: string
        required: false
      - paramName: expiresAfter
        description: The expiration policy for a vector store.
        paramKey: expires_after
        in: body
        schema:
          type: any
        required: false
      - paramName: metadata
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Vector Stores / Delete
    operationId: deleteVectorStore
    method: delete
    path: /vector_stores/{vector_store_id}
    description: Delete a vector store.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: The ID of the vector store to delete.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Vector Stores / Files / List
    operationId: listVectorStoreFiles
    method: get
    path: /vector_stores/{vector_store_id}/files
    description: Returns a list of vector store files.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: The ID of the vector store that the files belong to.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
      - paramName: limit
        description: >
          A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
      - paramName: order
        description: >
          Sort order by the `created_at` timestamp of the objects. `asc` for
          ascending order and `desc` for descending order.
        paramKey: order
        in: query
        schema:
          type: string
          default: desc
          enum:
            - asc
            - desc
        required: false
      - paramName: after
        description: >
          A cursor for use in pagination. `after` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include after=obj_foo in order to fetch the next page of the list.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: before
        description: >
          A cursor for use in pagination. `before` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include before=obj_foo in order to fetch the previous page of the
          list.
        paramKey: before
        in: query
        schema:
          type: string
        required: false
      - paramName: filter
        description: Filter by file status. One of `in_progress`, `completed`, `failed`,
          `cancelled`.
        paramKey: filter
        in: query
        schema:
          type: string
          enum:
            - in_progress
            - completed
            - failed
            - cancelled
        required: false
  - moduleName: Vector Stores / Files / Create
    operationId: createVectorStoreFile
    method: post
    path: /vector_stores/{vector_store_id}/files
    description: Create a vector store file by attaching a
      File to a vector store.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: |
          The ID of the vector store for which to create a File.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
      - paramName: fileId
        description: A File ID that the vector store should
          use. Useful for tools like `file_search` that can access files.
        paramKey: file_id
        in: body
        schema:
          type: string
        required: true
      - paramName: chunkingStrategy
        description: The chunking strategy used to chunk the file(s). If not set, will
          use the `auto` strategy.
        paramKey: chunking_strategy
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Vector Stores / Files / Retrieve
    operationId: getVectorStoreFile
    method: get
    path: /vector_stores/{vector_store_id}/files/{file_id}
    description: Retrieves a vector store file.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: The ID of the vector store that the file belongs to.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
      - paramName: fileId
        description: The ID of the file being retrieved.
        paramKey: file_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Vector Stores / Files / Delete
    operationId: deleteVectorStoreFile
    method: delete
    path: /vector_stores/{vector_store_id}/files/{file_id}
    description: Delete a vector store file. This will remove the file from the
      vector store but the file itself will not be deleted. To delete the file,
      use the delete endpoint.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: The ID of the vector store that the file belongs to.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
      - paramName: fileId
        description: The ID of the file to delete.
        paramKey: file_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Vector Stores / File Batches / Create
    operationId: createVectorStoreFileBatch
    method: post
    path: /vector_stores/{vector_store_id}/file_batches
    description: Create a vector store file batch.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: |
          The ID of the vector store for which to create a File Batch.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
      - paramName: fileIds
        description: A list of File IDs that the vector
          store should use. Useful for tools like `file_search` that can access
          files.
        paramKey: file_ids
        in: body
        schema:
          type: array
          items:
            type: any
        required: true
      - paramName: chunkingStrategy
        description: The chunking strategy used to chunk the file(s). If not set, will
          use the `auto` strategy.
        paramKey: chunking_strategy
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Vector Stores / File Batches / Retrieve
    operationId: getVectorStoreFileBatch
    method: get
    path: /vector_stores/{vector_store_id}/file_batches/{batch_id}
    description: Retrieves a vector store file batch.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: The ID of the vector store that the file batch belongs to.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
      - paramName: batchId
        description: The ID of the file batch being retrieved.
        paramKey: batch_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Vector Stores / File Batches / Cancel
    operationId: cancelVectorStoreFileBatch
    method: post
    path: /vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel
    description: Cancel a vector store file batch. This attempts to cancel the
      processing of files in this batch as soon as possible.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: The ID of the vector store that the file batch belongs to.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
      - paramName: batchId
        description: The ID of the file batch to cancel.
        paramKey: batch_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Vector Stores / File Batches / List Files
    operationId: listVectorStoreFileBatchFiles
    method: get
    path: /vector_stores/{vector_store_id}/file_batches/{batch_id}/files
    description: Returns a list of vector store files in a batch.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: vectorStoreId
        description: The ID of the vector store that the files belong to.
        paramKey: vector_store_id
        in: path
        schema:
          type: string
        required: true
      - paramName: batchId
        description: The ID of the file batch that the files belong to.
        paramKey: batch_id
        in: path
        schema:
          type: string
        required: true
      - paramName: limit
        description: >
          A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
      - paramName: order
        description: >
          Sort order by the `created_at` timestamp of the objects. `asc` for
          ascending order and `desc` for descending order.
        paramKey: order
        in: query
        schema:
          type: string
          default: desc
          enum:
            - asc
            - desc
        required: false
      - paramName: after
        description: >
          A cursor for use in pagination. `after` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include after=obj_foo in order to fetch the next page of the list.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: before
        description: >
          A cursor for use in pagination. `before` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include before=obj_foo in order to fetch the previous page of the
          list.
        paramKey: before
        in: query
        schema:
          type: string
        required: false
      - paramName: filter
        description: Filter by file status. One of `in_progress`, `completed`, `failed`,
          `cancelled`.
        paramKey: filter
        in: query
        schema:
          type: string
          enum:
            - in_progress
            - completed
            - failed
            - cancelled
        required: false
  - moduleName: Batches / Create
    operationId: createBatch
    method: post
    path: /batches
    description: Creates and executes a batch from an uploaded file of requests
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: inputFileId
        description: >
          The ID of an uploaded file that contains requests for the new batch.

          See upload file for how to upload a file.

          Your input file must be formatted as a JSONL, and must be uploaded
          with the purpose `batch`. The file can contain up to 50,000 requests,
          and can be up to 100 MB in size.
        paramKey: input_file_id
        in: body
        schema:
          type: string
        required: true
      - paramName: endpoint
        description: The endpoint to be used for all requests in the batch. Currently
          `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are
          supported. Note that `/v1/embeddings` batches are also restricted to a
          maximum of 50,000 embedding inputs across all requests in the batch.
        paramKey: endpoint
        in: body
        schema:
          type: string
          enum:
            - /v1/chat/completions
            - /v1/embeddings
            - /v1/completions
        required: true
      - paramName: completionWindow
        description: The time frame within which the batch should be processed.
          Currently only `24h` is supported.
        paramKey: completion_window
        in: body
        schema:
          type: string
          enum:
            - 24h
        required: true
      - paramName: metadata
        description: Optional custom metadata for the batch.
        paramKey: metadata
        in: body
        schema:
          type: any
        required: false
    requestBodyType: json
  - moduleName: Batches / List
    operationId: listBatches
    method: get
    path: /batches
    description: List your organization's batches.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: after
        description: >
          A cursor for use in pagination. `after` is an object ID that defines
          your place in the list. For instance, if you make a list request and
          receive 100 objects, ending with obj_foo, your subsequent call can
          include after=obj_foo in order to fetch the next page of the list.
        paramKey: after
        in: query
        schema:
          type: string
        required: false
      - paramName: limit
        description: >
          A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.
        paramKey: limit
        in: query
        schema:
          type: number
          default: 20
        required: false
  - moduleName: Batches / Retrieve
    operationId: retrieveBatch
    method: get
    path: /batches/{batch_id}
    description: Retrieves a batch.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: batchId
        description: The ID of the batch to retrieve.
        paramKey: batch_id
        in: path
        schema:
          type: string
        required: true
  - moduleName: Batches / Cancel
    operationId: cancelBatch
    method: post
    path: /batches/{batch_id}/cancel
    description: Cancels an in-progress batch. The batch will be in status
      `cancelling` for up to 10 minutes, before changing to `cancelled`, where
      it will have partial results (if any) available in the output file.
    externalDocs: https://platform.openai.com/docs/api-reference
    params:
      - paramName: batchId
        description: The ID of the batch to cancel.
        paramKey: batch_id
        in: path
        schema:
          type: string
        required: true
  